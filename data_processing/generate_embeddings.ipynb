{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is mostly run on Sagemaker studio. Running it locally is not recommended as it requires a lot of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from InstructorEmbedding import INSTRUCTOR\n",
    "\n",
    "import weaviate\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "weaviate_api_key = os.getenv('WEAVIATE_API_KEY')\n",
    "weaviate_url = os.getenv('WEAVIATE_URL')\n",
    "openai_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "client = weaviate.Client(\n",
    "    url = weaviate_url,\n",
    "    auth_client_secret=weaviate.AuthApiKey(api_key=weaviate_api_key), \n",
    "    additional_headers = {\n",
    "        \"X-OpenAI-Api-Key\": openai_key\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "combined_df = pd.read_csv(\"complete_cleaned_full_text.csv\")\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/msmarco-MiniLM-L12-cos-v5')\n",
    "# model = INSTRUCTOR('hkunlp/instructor-large')\n",
    "# instruction = \"Represent the legislation bills for retrieval:\"\n",
    "\n",
    "print(\"Max Sequence Length:\", model.max_seq_length)\n",
    "model.max_seq_length = 512\n",
    "\n",
    "for field in ['BillText', 'statesummary', 'ShortBillName']:\n",
    "    combined_df[f'{field}_vector'] = pd.Series(dtype='object')\n",
    "\n",
    "for index, row in tqdm(combined_df.iterrows(), total=combined_df.shape[0]):\n",
    "    # Vectorize the specified fields\n",
    "    for field in ['BillText', 'statesummary', 'ShortBillName']:\n",
    "        field_value = row[field]\n",
    "        \n",
    "        if pd.notna(field_value):\n",
    "            vector = model.encode(str(field_value)).tolist()  # Ensure field_value is string\n",
    "            combined_df.at[index, f'{field}_vector'] = vector\n",
    "        else:\n",
    "            combined_df.at[index, f'{field}_vector'] = []\n",
    "\n",
    "combined_df.to_csv(\"combined_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def clean_vector(vector):\n",
    "    # Check if the vector is not None and is a list\n",
    "    if vector is not None and isinstance(vector, list):\n",
    "        # Replace NaN or Inf values with 0\n",
    "        return [0 if np.isnan(x) or np.isinf(x) else x for x in vector]\n",
    "    else:\n",
    "        # If the vector is None or not a list, return an empty list or a default vector\n",
    "        return []\n",
    "\n",
    "for field in ['BillText_vector', 'statesummary_vector', 'ShortBillName_vector']:\n",
    "    combined_df[field] = combined_df[field].apply(clean_vector)\n",
    "    \n",
    "    \n",
    "if client.schema.exists(\"Legislation\"):\n",
    "    client.schema.delete_class(\"Legislation\")\n",
    "    \n",
    "# for pre-vectorized data\n",
    "class_obj = {\n",
    "    \"class\": \"Legislation\",\n",
    "    \"vectorizer\": \"none\",\n",
    "    \"moduleConfig\": {\n",
    "        \"generative-openai\": {}  # Ensure the `generative-openai` module is used for generative queries\n",
    "    }\n",
    "}\n",
    "\n",
    "client.schema.create_class(class_obj)\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# for pre-vectorized data        \n",
    "client.batch.configure(batch_size=100)\n",
    "\n",
    "with client.batch as batch:\n",
    "    # Wrap combined_df.iterrows() with tqdm for a progress bar\n",
    "    for index, row in tqdm(combined_df.iterrows(), total=combined_df.shape[0]):\n",
    "        try:\n",
    "            bill_text_vector = clean_vector(row.get('BillText_vector', []))\n",
    "\n",
    "            properties = {\n",
    "                \"BillID\": row['BillID'],\n",
    "                \"StateCode\": row['StateCode'],\n",
    "                \"StateBillID\": row['StateBillID'],            \n",
    "                \"ShortBillName\": row['ShortBillName'],\n",
    "                \"Created\": row['Created'],\n",
    "                \"SponsorParty\": row['SponsorParty'],\n",
    "                \"billtype\": row['billtype'],\n",
    "                \"status\": row['status'],\n",
    "                \"CommitteeCategories\": row['CommitteeCategories'],\n",
    "                \"statesummary\": row['statesummary'],\n",
    "                \"BillText\": row['BillText']\n",
    "            }\n",
    "\n",
    "            # Attempt to add the data object to the batch\n",
    "            batch.add_data_object(properties, \"Legislation\", vector=bill_text_vector)\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Log the error and skip this record\n",
    "            print(f\"Skipping record at index {index} due to error: {e}\")\n",
    "            continue  # Skip the rest of the current loop iteration\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
