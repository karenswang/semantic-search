{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your data (adjust the path as needed)\n",
    "wapo_data = pd.read_csv('../benchmark_data/fatal-police-shootings-data.csv')\n",
    "police_dept = pd.read_csv('../benchmark_data/fatal-police-shootings-agencies.csv')\n",
    "# print(wapo_data)\n",
    "# Define common suffixes to ignore\n",
    "common_suffixes = ['Jr', 'Sr', 'II', 'III', 'IV', 'V']\n",
    "\n",
    "# Define a function that processes each name\n",
    "def process_name(name):\n",
    "    # Ensure name is a string and not NaN or any float value\n",
    "    if pd.isnull(name):\n",
    "        # Handle NaN values or any other non-string values\n",
    "        return [None, None]  # Or return ['Unknown', 'Unknown'] based on your preference\n",
    "    else:\n",
    "        # Convert to string in case it's not (handles numeric values)\n",
    "        name = str(name)\n",
    "        # Split the name into parts\n",
    "        parts = name.split()\n",
    "        # Check and construct the name ignoring common suffixes and middle names\n",
    "        if parts[-1] in common_suffixes and len(parts) > 2:\n",
    "            first_last_name = f\"{parts[0]} {parts[-2]}\"\n",
    "        elif len(parts) > 2:\n",
    "            first_last_name = f\"{parts[0]} {parts[-1]}\"\n",
    "        else:\n",
    "            first_last_name = name\n",
    "        # Return a list with the original name, the first-last name version, and the version ignoring suffixes\n",
    "        return [name, first_last_name]\n",
    "\n",
    "# Apply the function to the 'name' column and create a new column with the results\n",
    "wapo_data['names'] = wapo_data['name'].apply(process_name)\n",
    "# wapo_data['date'] = pd.to_datetime(wapo_data['date'])\n",
    "wapo_data = wapo_data[(wapo_data['date'] >= '2023-12-01') & (wapo_data['date'] <= '2023-12-15')]\n",
    "\n",
    "result = pd.read_csv('../data_storage/benchmark/benchmark_large.csv')\n",
    "# result['publication_date'] = pd.to_datetime(result['publication_date'])\n",
    "wapo_data.reset_index(drop=True, inplace=True)\n",
    "result_hit = result[result['Hit?']==\"Y\"]\n",
    "print(result_hit.shape)\n",
    "print(result.shape)\n",
    "# wapo_data\n",
    "\n",
    "import numpy as np\n",
    "from dateutil import tz\n",
    "\n",
    "\n",
    "def parse_closest_date(wapo_date, publication_dates_str):\n",
    "    # Ensure wapo_date is tz-naive\n",
    "    wapo_date = wapo_date.replace(tzinfo=None)\n",
    "    \n",
    "    # Split the string into individual dates and remove any whitespace\n",
    "    date_str_list = publication_dates_str.strip().replace('(', '').replace(')', '').split(',')\n",
    "    \n",
    "    # Convert string dates to datetime and ensure they are tz-naive\n",
    "    date_diffs = [abs(wapo_date - pd.to_datetime(date_str.strip(), utc=True).replace(tzinfo=None)).days for date_str in date_str_list]\n",
    "    \n",
    "    # Return the date with the minimum difference\n",
    "    min_diff_index = np.argmin(date_diffs)\n",
    "    return pd.to_datetime(date_str_list[min_diff_index].strip(), utc=True).replace(tzinfo=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([ 2,  5, 11, 13, 14, 20, 21, 22, 24, 26, 29, 33, 34, 37, 38, 40, 42, 45,\n",
      "       48, 50, 52, 54, 55],\n",
      "      dtype='int64')\n",
      "True conditions: 23 out of 57 rows.\n"
     ]
    }
   ],
   "source": [
    "# Assuming the preparation steps have been done as in your provided code\n",
    "\n",
    "# Helper function to check conditions\n",
    "def check_conditions(row, results_df, police_dept):\n",
    "    # Ensure 'names' is a list of strings, filtering out any None values\n",
    "    names = [str(name) for name in row['names'] if pd.notnull(name)]\n",
    "    \n",
    "    # Check if any name in 'names' appears in 'snippet'\n",
    "    for name in names:\n",
    "        if any(name in str(snippet) for snippet in results_df['snippet']):\n",
    "            return True\n",
    "    \n",
    "    # Convert 'date' to datetime for comparison\n",
    "    wapo_date = pd.to_datetime(row['date'])\n",
    "    \n",
    "    # Ensure 'city' and 'county' are strings, handling potential NaN values\n",
    "    city = str(row['city']) if pd.notnull(row['city']) else \"\"\n",
    "    county = str(row['county']) if pd.notnull(row['county']) else \"\"\n",
    "    \n",
    "    # Check if 'city' appears in 'snippet' and dates within 7 days\n",
    "    city_condition = results_df.apply(lambda x: city in str(x['snippet']) and abs((wapo_date - parse_closest_date(wapo_date, x['publication_date'])).days) <= 7, axis=1)\n",
    "    if city_condition.any():\n",
    "        return True\n",
    "    \n",
    "    # Check if 'county' appears in 'snippet' and dates within 5 days\n",
    "    county_condition = results_df.apply(lambda x: county in str(x['snippet']) and abs((wapo_date - parse_closest_date(wapo_date, x['publication_date'])).days) <= 5, axis=1)\n",
    "    if county_condition.any():\n",
    "        return True\n",
    "    \n",
    "    agency_id = row['agency_ids']\n",
    "    if pd.notnull(agency_id):\n",
    "        # Find the corresponding name in 'police_dept' for the given 'agency_id'\n",
    "        agency_name = police_dept.loc[police_dept['id'] == agency_id, 'name'].values\n",
    "        if len(agency_name) > 0:  # Ensure there is a match\n",
    "            agency_name = str(agency_name[0])  # Convert to string in case it's not\n",
    "            # Check if the agency name appears in 'snippet' and dates within 5 days\n",
    "            agency_condition = results_df.apply(lambda x: agency_name in str(x['snippet']) and abs((wapo_date - parse_closest_date(wapo_date, x['publication_date'])).days) <= 5, axis=1)\n",
    "            if agency_condition.any():\n",
    "                return True\n",
    "\n",
    "    # If none of the conditions are met\n",
    "    return False\n",
    "\n",
    "\n",
    "# Apply the helper function to each row in wapo_data\n",
    "wapo_data['condition_met'] = wapo_data.apply(check_conditions, results_df=result, police_dept=police_dept, axis=1)\n",
    "\n",
    "idx = wapo_data.index[wapo_data['condition_met']]\n",
    "print(idx)\n",
    "\n",
    "# Print summary\n",
    "true_count = wapo_data['condition_met'].sum()\n",
    "total_rows = len(wapo_data)\n",
    "print(f\"True conditions: {true_count} out of {total_rows} rows.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from waybacknews.searchapi import SearchApiClient\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import requests\n",
    "from retrying import retry\n",
    "import requests_cache\n",
    "from tqdm import tqdm\n",
    "# import mediacloud.api\n",
    "# from newspaper import Article\n",
    "# import unicodedata\n",
    "import concurrent.futures\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from InstructorEmbedding import INSTRUCTOR\n",
    "from openai import OpenAI\n",
    "\n",
    "import weaviate\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "weaviate_api_key = os.getenv('WEAVIATE_API_KEY')\n",
    "weaviate_url = os.getenv('WEAVIATE_URL')\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "client = weaviate.Client(\n",
    "    url = weaviate_url,\n",
    "    auth_client_secret=weaviate.AuthApiKey(api_key=weaviate_api_key), \n",
    "    additional_headers = {\n",
    "        \"X-OpenAI-Api-Key\": OPENAI_API_KEY\n",
    "    }\n",
    ")\n",
    "\n",
    "openai_client = OpenAI()\n",
    "\n",
    "\n",
    "query_text = \"\"\"\n",
    "Breaking news coverage on recent police shooting incidents in the United States leading to fatalities of the victims. The incidents are about police officer, deputy, sheriff, trooper, cop who fired shots and killed someone.\n",
    "Do not include aggregated summary, list, or archive of incidents happened in the past. Do not include if it's about a past, not recent incident. Only include if the story mentioned the death of the victim.\n",
    "Do not include if it's coverage on legal proceedings, court cases, or trials of a past incident. Do not include if it's about the aftermath of the incident, such as protests, rallies, or demonstrations on a past incident.\n",
    "Do not include if it happened in a foreign country, only include if it's about the United States.\n",
    "\"\"\"\n",
    "instruction_prompt = \"Represent the news articles for retrieval:\"\n",
    "\n",
    "# # Using the text-embedding-3-large model to generate embeddings\n",
    "# response = openai_client.embeddings.create(\n",
    "#     input=query_text,\n",
    "#     model=\"text-embedding-3-small\"\n",
    "# )\n",
    "# query_vector = response.data[0].embedding\n",
    "\n",
    "# query_model = SentenceTransformer(\"nomic-ai/nomic-embed-text-v1\")\n",
    "\n",
    "# query_vector = query_model.encode(query_text).tolist()\n",
    "\n",
    "\n",
    "query_model = SentenceTransformer(\"nomic-ai/nomic-embed-text-v1\")\n",
    "query_vector = query_model.encode(query_text, convert_to_tensor=True)\n",
    "\n",
    "# query_vector = embed_model.encode([[instruction_prompt,query_text]]).tolist()\n",
    "# query_vector = [item for sublist in query_vector for item in sublist]\n",
    "print(\"vector:\", query_vector.__len__())\n",
    "\n",
    "get_articles_group = f\"\"\"\n",
    "{{\n",
    "  Get {{\n",
    "    Article(\n",
    "      nearVector: {{\n",
    "        vector: {query_vector}\n",
    "      }},\n",
    "      group: {{\n",
    "        type: merge,\n",
    "        force: 0\n",
    "      }},\n",
    "      limit: 80\n",
    "    ) {{\n",
    "      title,\n",
    "      publication_date,\n",
    "      snippet\n",
    "    }}\n",
    "  }}\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "query_result = client.query.raw(get_articles_group)\n",
    "# save to csv\n",
    "df = pd.DataFrame(query_result['data']['Get']['Article'])\n",
    "df.to_csv(f'./data_storage/{timestamp}_test_weaviate_result.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semantic-search",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
